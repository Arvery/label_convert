dataset:
  # if type==voc,voc_path cannot be empty, if type==base,train:images_path/masks_path cannot be empty
  type: base                                                      # base / coco / voc
  voc_root:                                                      # only use for voc

  train:
    images_path: E:\dataset\segmentation\car\train_images       # only use for base
    masks_path: E:\dataset\segmentation\car\train_masks         # only use for base
  val:
    images_path:                                                # if empty,20% from train as val
    masks_path:                                                 # if empty,20% from train as val


model:
  name: deeplabv3_resnet50                                      # model name
  backbone: resnet50                                            # backbone
  use_aux: True                                                 # aux
  pretrain_backbone: False                                      # if True,use pretrain backbone weights
  pretrain_weights: deeplabv3_resnet50_coco-cd0a2569.pth                                            # path of pretrain model weights

train:
  # log
  logging_name: deeplabv3_car_sgd_lr_0.001                                               # logging file name
  num_classes: 1                                                           # classes number without background

  # train loader
  batch_size: 16                                                             # bs
  num_workers: 0                                                            # nw

  ignore_index: 255                                                         # train without ignore_label
  label_mapping: #{ 0: 0,1: 1,3: 255 }                                      # label convert

  base_size: (500,500)                                                      # base size (h w) int(s) or tuple(h,w)
  crop_size: (480,480)                                                      # input size, random crop (h,w) int(s) or tuple(h,w)
  ratio: (0.5,2.0)                                                          # random size = base_size * r
  mean: [ 0.485, 0.456, 0.406 ]                                               # normalization mean
  std: [ 0.229, 0.224, 0.225 ]                                                # normalization std

  # train model
  use_gpu: Ture                                                             # use cuda
  amp: False                                                                # if True, Use torch.cuda.amp for mixed precision training"
  start_epoch: 0                                                            # start epoch
  epochs: 30                                                               # train epochs
  resume:                                                                   # checkpoint path, resume from the checkpoint

  # eval
  print_freq: 30                                                            # every 30 iter,print result
  eval_step: 1                                                              # every 1 opoch, eval

optimizer: # optimizer
  name: SGD
  params:
    lr: 0.001
    momentum: 0.9
    weight_decay: 0.0001

# loss
criterion:
  name: 'CrossEntropy'                                                     # CrossEntropy
  params:
    ignore_index: 255                                                      # train without ignore_label
    weight: #[ 1.0,1.0 ]                                                    # loss weights of per class

  # lr_schedule
scheduler:
  name: 'LambdaLR'
  params:
    lr_lambda: